{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(0)\n",
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "# Create DataLoaders for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=30720, out_features=65, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=65, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Simpler model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(65, 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128*240, 65)  \n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
    "        self.fc3 = nn.Linear(65, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Initialize the network and print its architecture\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 3.0144\n",
      "Epoch 2, training loss: 2.0268\n",
      "Epoch 3, training loss: 1.3780\n",
      "Epoch 4, training loss: 1.0252\n",
      "Epoch 5, training loss: 0.8956\n",
      "Epoch 6, training loss: 0.8356\n",
      "Epoch 7, training loss: 0.8230\n",
      "Epoch 8, training loss: 0.8027\n",
      "Epoch 9, training loss: 0.8040\n",
      "Epoch 10, training loss: 0.8018\n",
      "Epoch 11, training loss: 0.7677\n",
      "Epoch 12, training loss: 0.7583\n",
      "Epoch 13, training loss: 0.7618\n",
      "Epoch 14, training loss: 0.7770\n",
      "Epoch 15, training loss: 0.7990\n",
      "Epoch 1, training loss: 0.7308\n",
      "Epoch 2, training loss: 0.6901\n",
      "Epoch 3, training loss: 0.6770\n",
      "Epoch 4, training loss: 0.6147\n",
      "Epoch 5, training loss: 0.5677\n",
      "Epoch 6, training loss: 0.4948\n",
      "Epoch 7, training loss: 0.4114\n",
      "Epoch 8, training loss: 0.3996\n",
      "Epoch 9, training loss: 0.3288\n",
      "Epoch 10, training loss: 0.2399\n",
      "Epoch 11, training loss: 0.2265\n",
      "Epoch 12, training loss: 0.1683\n",
      "Epoch 13, training loss: 0.1567\n",
      "Epoch 14, training loss: 0.1151\n",
      "Epoch 15, training loss: 0.1041\n",
      "Epoch 16, training loss: 0.1024\n",
      "Epoch 17, training loss: 0.0746\n",
      "Epoch 18, training loss: 0.0625\n",
      "Epoch 19, training loss: 0.0756\n",
      "Epoch 20, training loss: 0.0553\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.5,1.0]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Initialize empty lists to store losses\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        l1_lambda = 0.0005\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss+=l1_lambda*l1_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Compute training loss\n",
    "        train_losses.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "# Now without regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Compute training loss\n",
    "        train_losses.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = original_model.conv1\n",
    "        self.fc1 = original_model.fc1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Create the new model\n",
    "new_model = MyModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,32,65).\n",
    "labels_train = []\n",
    "for data in train_dataloader:\n",
    "    input_data = data[0].float()\n",
    "    labels_train.append(data[1])\n",
    "    output = new_model(input_data.to(device)) #Shape (*, 65)\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "flattened_labels = np.concatenate(labels_train, axis = 0)\n",
    "del outputs, output\n",
    "np.save('modified_train.npy', flattened_outputs)\n",
    "np.save('modified_labels.npy', flattened_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataloader, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "outputs_2 = []\n",
    "# Assuming x_test is a PyTorch tensor\n",
    "testloader = torch.utils.data.DataLoader(X_test, batch_size=32)\n",
    "del X_test\n",
    "for data in testloader:\n",
    "    input_data = data.float()\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs_2.append(output.detach().cpu().numpy()) \n",
    "\n",
    "\n",
    "flattened_outputs_2 = np.concatenate(outputs_2, axis=0)\n",
    "del outputs_2, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('modified_test.npy',flattened_outputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('modified_train.npy')\n",
    "y_train = np.load('modified_labels.npy')\n",
    "x_test = np.load('modified_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 65)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.49214\n",
      "[1]\tvalidation_0-logloss:0.36837\n",
      "[2]\tvalidation_0-logloss:0.28666\n",
      "[3]\tvalidation_0-logloss:0.23350\n",
      "[4]\tvalidation_0-logloss:0.18804\n",
      "[5]\tvalidation_0-logloss:0.14829\n",
      "[6]\tvalidation_0-logloss:0.12166\n",
      "[7]\tvalidation_0-logloss:0.09662\n",
      "[8]\tvalidation_0-logloss:0.08514\n",
      "[9]\tvalidation_0-logloss:0.07037\n",
      "[10]\tvalidation_0-logloss:0.06160\n",
      "[11]\tvalidation_0-logloss:0.05388\n",
      "[12]\tvalidation_0-logloss:0.04850\n",
      "[13]\tvalidation_0-logloss:0.04394\n",
      "[14]\tvalidation_0-logloss:0.04018\n",
      "[15]\tvalidation_0-logloss:0.03495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tvalidation_0-logloss:0.03199\n",
      "[17]\tvalidation_0-logloss:0.02878\n",
      "[18]\tvalidation_0-logloss:0.02704\n",
      "[19]\tvalidation_0-logloss:0.02514\n",
      "[20]\tvalidation_0-logloss:0.02263\n",
      "[21]\tvalidation_0-logloss:0.02274\n",
      "[22]\tvalidation_0-logloss:0.02266\n",
      "[23]\tvalidation_0-logloss:0.02096\n",
      "[24]\tvalidation_0-logloss:0.02030\n",
      "[25]\tvalidation_0-logloss:0.01940\n",
      "[26]\tvalidation_0-logloss:0.01840\n",
      "[27]\tvalidation_0-logloss:0.01843\n",
      "[28]\tvalidation_0-logloss:0.01781\n",
      "[29]\tvalidation_0-logloss:0.01655\n",
      "[30]\tvalidation_0-logloss:0.01661\n",
      "[31]\tvalidation_0-logloss:0.01642\n",
      "[32]\tvalidation_0-logloss:0.01682\n",
      "[33]\tvalidation_0-logloss:0.01669\n",
      "[34]\tvalidation_0-logloss:0.01631\n",
      "[35]\tvalidation_0-logloss:0.01565\n",
      "[36]\tvalidation_0-logloss:0.01547\n",
      "[37]\tvalidation_0-logloss:0.01582\n",
      "[38]\tvalidation_0-logloss:0.01561\n",
      "[39]\tvalidation_0-logloss:0.01552\n",
      "[40]\tvalidation_0-logloss:0.01538\n",
      "[41]\tvalidation_0-logloss:0.01532\n",
      "[42]\tvalidation_0-logloss:0.01509\n",
      "[43]\tvalidation_0-logloss:0.01500\n",
      "[44]\tvalidation_0-logloss:0.01495\n",
      "[45]\tvalidation_0-logloss:0.01454\n",
      "[46]\tvalidation_0-logloss:0.01452\n",
      "[47]\tvalidation_0-logloss:0.01446\n",
      "[48]\tvalidation_0-logloss:0.01446\n",
      "[49]\tvalidation_0-logloss:0.01445\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Suppose 'data' is your 2D numpy array, with each row a datapoint\n",
    "# And 'labels' is a 1D numpy array containing the class label for each datapoint\n",
    "data = np.vstack((x_train,x_test[:50]))  # Your data\n",
    "labels = np.hstack((y_train,y_test[:50]))  # Your labels\n",
    "\n",
    "# Split the data into training and testing sets first\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scale_pos_weight = sum(labels_train == 0) / sum(labels_train == 1)\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier(\n",
    "    max_depth=2,  # Maximum depth of the trees\n",
    "    learning_rate=0.3,  # Learning rate (eta)\n",
    "    n_estimators=50,  # Number of training rounds\n",
    "    objective='binary:logistic',  # Objective function for binary classification\n",
    "    scale_pos_weight = scale_pos_weight,\n",
    "    random_state=42  # Random seed\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "eval_set = [(data_test, labels_test)]  # Validation set for early stopping\n",
    "model.fit(data_train, labels_train,eval_metric=\"logloss\", eval_set=eval_set)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_prob = model.predict_proba(data_test)\n",
    "\n",
    "# 'preds_prob' now contains the predicted probabilities of the positive class for each datapoint in the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.998, 0.002],\n",
       "       [1.   , 0.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.006, 0.994],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.999, 0.001],\n",
       "       [0.997, 0.003],\n",
       "       [0.   , 1.   ],\n",
       "       [0.92 , 0.08 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.001, 0.999],\n",
       "       [0.   , 1.   ],\n",
       "       [0.999, 0.001],\n",
       "       [0.01 , 0.99 ],\n",
       "       [0.996, 0.004],\n",
       "       [0.005, 0.995],\n",
       "       [0.   , 1.   ],\n",
       "       [0.002, 0.998],\n",
       "       [0.999, 0.001],\n",
       "       [0.998, 0.002],\n",
       "       [0.998, 0.002],\n",
       "       [0.007, 0.993],\n",
       "       [1.   , 0.   ],\n",
       "       [0.996, 0.004],\n",
       "       [0.002, 0.998],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ],\n",
       "       [0.998, 0.002],\n",
       "       [0.   , 1.   ],\n",
       "       [0.999, 0.001],\n",
       "       [0.004, 0.996],\n",
       "       [1.   , 0.   ],\n",
       "       [0.991, 0.009],\n",
       "       [0.999, 0.001],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.082, 0.918],\n",
       "       [0.999, 0.001],\n",
       "       [0.001, 0.999],\n",
       "       [0.999, 0.001],\n",
       "       [0.985, 0.015],\n",
       "       [0.999, 0.001],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ],\n",
       "       [0.725, 0.275],\n",
       "       [0.002, 0.998],\n",
       "       [0.998, 0.002],\n",
       "       [0.993, 0.007],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.999, 0.001],\n",
       "       [0.995, 0.005],\n",
       "       [0.999, 0.001],\n",
       "       [0.017, 0.983],\n",
       "       [0.997, 0.003],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.999, 0.001],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.013, 0.987],\n",
       "       [0.003, 0.997],\n",
       "       [0.998, 0.002],\n",
       "       [1.   , 0.   ],\n",
       "       [0.997, 0.003],\n",
       "       [1.   , 0.   ],\n",
       "       [0.003, 0.997],\n",
       "       [0.979, 0.021],\n",
       "       [0.799, 0.201],\n",
       "       [0.95 , 0.05 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.001, 0.999],\n",
       "       [0.997, 0.003],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.262, 0.738],\n",
       "       [0.   , 1.   ],\n",
       "       [0.998, 0.002],\n",
       "       [0.002, 0.998],\n",
       "       [0.999, 0.001],\n",
       "       [0.001, 0.999],\n",
       "       [0.001, 0.999],\n",
       "       [0.916, 0.084],\n",
       "       [1.   , 0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds_prob,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Make predictions on the test set\n",
    "def find_optimal_threshold(predictions, y_test):\n",
    "    min_sum = float('inf')\n",
    "    optimal_threshold = 0\n",
    "\n",
    "    # Iterate over possible thresholds from 0 to 1\n",
    "    for threshold in np.arange(0.0, 1, 0.001):\n",
    "        # Apply threshold\n",
    "        preds = (np.array(predictions)[:,1] > threshold).astype(int)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "        # Compute sum of off-diagonal elements\n",
    "        off_diagonal_sum = 164 - np.trace(cm)\n",
    "        #print(cm)\n",
    "        # Update optimal threshold if this threshold is better\n",
    "        if off_diagonal_sum < min_sum and cm[1][1]/np.sum(cm[1]) >0.5:\n",
    "            min_sum = off_diagonal_sum\n",
    "            optimal_threshold = threshold\n",
    "\n",
    "    return optimal_threshold\n",
    "\n",
    "threshold = find_optimal_threshold(preds_prob, labels_test)\n",
    "preds = (preds_prob[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68,  0],\n",
       "       [ 0, 27]], dtype=int64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1.]), array([1., 1.]), array([1., 1.]))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict_proba(x_test[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = find_optimal_threshold(pred_test, y_test[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6522727272727273"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (pred_test[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test[50:], preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "roc_auc_score(y_test[50:], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 13],\n",
       "       [10, 15]], dtype=int64)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[50:], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75609756, 0.53571429]),\n",
       " array([0.70454545, 0.6       ]),\n",
       " array([0.72941176, 0.56603774]))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(y_test[50:], preds)\n",
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.95       1.         0.97435897 1.         1.         0.97435897]\n",
      "Average cross-validation score:  0.9831196581196581\n",
      "[0]\tvalidation_0-logloss:0.56500\n",
      "[1]\tvalidation_0-logloss:0.47972\n",
      "[2]\tvalidation_0-logloss:0.39767\n",
      "[3]\tvalidation_0-logloss:0.33341\n",
      "[4]\tvalidation_0-logloss:0.29346\n",
      "[5]\tvalidation_0-logloss:0.25361\n",
      "[6]\tvalidation_0-logloss:0.22242\n",
      "[7]\tvalidation_0-logloss:0.19370\n",
      "[8]\tvalidation_0-logloss:0.16665\n",
      "[9]\tvalidation_0-logloss:0.15233\n",
      "[10]\tvalidation_0-logloss:0.13736\n",
      "[11]\tvalidation_0-logloss:0.12367\n",
      "[12]\tvalidation_0-logloss:0.11410\n",
      "[13]\tvalidation_0-logloss:0.10214\n",
      "[14]\tvalidation_0-logloss:0.09282\n",
      "[15]\tvalidation_0-logloss:0.08472\n",
      "[16]\tvalidation_0-logloss:0.07795\n",
      "[17]\tvalidation_0-logloss:0.07128\n",
      "[18]\tvalidation_0-logloss:0.06567\n",
      "[19]\tvalidation_0-logloss:0.06323\n",
      "[20]\tvalidation_0-logloss:0.05928\n",
      "[21]\tvalidation_0-logloss:0.05518\n",
      "[22]\tvalidation_0-logloss:0.05150\n",
      "[23]\tvalidation_0-logloss:0.04906\n",
      "[24]\tvalidation_0-logloss:0.04702\n",
      "[25]\tvalidation_0-logloss:0.04443\n",
      "[26]\tvalidation_0-logloss:0.04250\n",
      "[27]\tvalidation_0-logloss:0.04106\n",
      "[28]\tvalidation_0-logloss:0.03940\n",
      "[29]\tvalidation_0-logloss:0.03710\n",
      "[30]\tvalidation_0-logloss:0.03693\n",
      "[31]\tvalidation_0-logloss:0.03601\n",
      "[32]\tvalidation_0-logloss:0.03491\n",
      "[33]\tvalidation_0-logloss:0.03397\n",
      "[34]\tvalidation_0-logloss:0.03234\n",
      "[35]\tvalidation_0-logloss:0.03173\n",
      "[36]\tvalidation_0-logloss:0.03043\n",
      "[37]\tvalidation_0-logloss:0.02975\n",
      "[38]\tvalidation_0-logloss:0.02909\n",
      "[39]\tvalidation_0-logloss:0.02800\n",
      "[40]\tvalidation_0-logloss:0.02745\n",
      "[41]\tvalidation_0-logloss:0.02686\n",
      "[42]\tvalidation_0-logloss:0.02701\n",
      "[43]\tvalidation_0-logloss:0.02634\n",
      "[44]\tvalidation_0-logloss:0.02616\n",
      "[45]\tvalidation_0-logloss:0.02559\n",
      "[46]\tvalidation_0-logloss:0.02542\n",
      "[47]\tvalidation_0-logloss:0.02532\n",
      "[48]\tvalidation_0-logloss:0.02484\n",
      "[49]\tvalidation_0-logloss:0.02474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Suppose 'data' is your 2D numpy array, with each row a datapoint\n",
    "# And 'labels' is a 1D numpy array containing the class label for each datapoint\n",
    "data = np.vstack((x_train,x_test[:50]))  # Your data\n",
    "labels = np.hstack((y_train,y_test[:50]))  # Your labels\n",
    "\n",
    "# Split the data into training and testing sets first\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(x_train, y_train, test_size=0.5, random_state=42, stratify = y_train)\n",
    "\n",
    "scale_pos_weight = sum(labels_train == 0) / sum(labels_train == 1)\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier(\n",
    "    max_depth=2,  # Maximum depth of the trees\n",
    "    learning_rate=0.2,  # Learning rate (eta)\n",
    "    n_estimators=50,  # Number of training rounds\n",
    "    objective='binary:logistic',  # Objective function for binary classification\n",
    "    scale_pos_weight = scale_pos_weight,\n",
    "    reg_lambda = 1, #L2 regularization\n",
    "    random_state=42  # Random seed\n",
    ")\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, data_train, labels_train, cv=6)\n",
    "\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())\n",
    "\n",
    "# Train the model with early stopping\n",
    "eval_set = [(data_test, labels_test)]  # Validation set for early stopping\n",
    "model.fit(data_train, labels_train,eval_metric=\"logloss\", eval_set=eval_set, early_stopping_rounds = 10)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_prob = model.predict_proba(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " array([[163,   0],\n",
       "        [  0,  73]], dtype=int64))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Make predictions on the test set\n",
    "def find_optimal_threshold(predictions, y_test):\n",
    "    min_sum = float('inf')\n",
    "    optimal_threshold = 0\n",
    "\n",
    "    # Iterate over possible thresholds from 0 to 1\n",
    "    for threshold in np.arange(0.0, 1, 0.001):\n",
    "        # Apply threshold\n",
    "        preds = (np.array(predictions)[:,1] > threshold).astype(int)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "        # Compute sum of off-diagonal elements\n",
    "        off_diagonal_sum = 164 - np.trace(cm)\n",
    "        #print(cm)\n",
    "        # Update optimal threshold if this threshold is better\n",
    "        if off_diagonal_sum < min_sum and cm[1][1]/np.sum(cm[1]) >0.5:\n",
    "            min_sum = off_diagonal_sum\n",
    "            optimal_threshold = threshold\n",
    "\n",
    "    return optimal_threshold\n",
    "\n",
    "threshold = find_optimal_threshold(preds_prob, labels_test)\n",
    "preds = (preds_prob[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(labels_test, preds), confusion_matrix(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1.]), array([1., 1.]), array([1., 1.]))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(labels_test, preds)\n",
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.22%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6495454545454546,\n",
       " array([[29, 15],\n",
       "        [ 9, 16]], dtype=int64))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict_proba(x_test[50:])\n",
    "threshold = find_optimal_threshold(pred_test, y_test[50:])\n",
    "preds = (pred_test[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test[50:], preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "roc_auc_score(y_test[50:], preds), confusion_matrix(y_test[50:], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.76315789, 0.51612903]),\n",
       " array([0.65909091, 0.64      ]),\n",
       " array([0.70731707, 0.57142857]))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(y_test[50:], preds)\n",
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8209069,
     "datasetId": 4773921,
     "sourceId": 8092331,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
