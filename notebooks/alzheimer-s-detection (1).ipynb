{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport os\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"5e3bbedd-c862-4060-9174-8f328e43f721","_cell_guid":"28fc7583-37c8-4c12-a0d5-77a2e08b6c48","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-28T09:42:43.939426Z","iopub.execute_input":"2024-03-28T09:42:43.939809Z","iopub.status.idle":"2024-03-28T09:42:48.334490Z","shell.execute_reply.started":"2024-03-28T09:42:43.939773Z","shell.execute_reply":"2024-03-28T09:42:48.333676Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path1 = []\npath2 = []\npath3 = []\npath0 = []\nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Non Demented'):\n    for filename in filenames:\n        path0.append(os.path.join(dirname, filename))\n        \nprint('First done')\nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Mild Dementia'):\n    for filename in filenames:\n        path1.append(os.path.join(dirname, filename))\n        \nprint('Second done')\nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Moderate Dementia'):\n    for filename in filenames:\n        path3.append(os.path.join(dirname, filename))\n        \nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Very mild Dementia'):\n    for filename in filenames:\n        path2.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:42:48.336176Z","iopub.execute_input":"2024-03-28T09:42:48.336597Z","iopub.status.idle":"2024-03-28T09:44:25.602096Z","shell.execute_reply.started":"2024-03-28T09:42:48.336572Z","shell.execute_reply":"2024-03-28T09:44:25.601320Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"First done\nSecond done\n","output_type":"stream"}]},{"cell_type":"code","source":"4+6","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.603150Z","iopub.execute_input":"2024-03-28T09:44:25.603461Z","iopub.status.idle":"2024-03-28T09:44:25.610290Z","shell.execute_reply.started":"2024-03-28T09:44:25.603436Z","shell.execute_reply":"2024-03-28T09:44:25.609312Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"def create_dict(file_names):\n    img_dict = {}\n    for name in file_names:\n        ind = name[:-8]\n        if ind in img_dict:\n            img_dict[ind].append(name)\n        else:\n            dem = name[31:34]\n            if dem=='Non':\n                img_dict[ind] = [0]\n            elif dem == 'Mil':\n                img_dict[ind] = [1]\n            elif dem == 'Ver':\n                img_dict[ind] = [2]\n            else:\n                img_dict[ind] = [3]\n            img_dict[ind].append(name)\n    return img_dict\nimg_dict = create_dict(path0 + path1 + path2 + path3)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.612768Z","iopub.execute_input":"2024-03-28T09:44:25.613387Z","iopub.status.idle":"2024-03-28T09:44:25.667294Z","shell.execute_reply.started":"2024-03-28T09:44:25.613354Z","shell.execute_reply":"2024-03-28T09:44:25.666614Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def create_df_from_dict(img_dict):\n    df = pd.DataFrame({k: v[0] for k,v in img_dict.items()}, index = ['Class']).T\n    return df\ndf_all = create_df_from_dict(img_dict)\ndf_all.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.668365Z","iopub.execute_input":"2024-03-28T09:44:25.668671Z","iopub.status.idle":"2024-03-28T09:44:25.710990Z","shell.execute_reply.started":"2024-03-28T09:44:25.668639Z","shell.execute_reply":"2024-03-28T09:44:25.710054Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                    Class\n/kaggle/input/imagesoasis/Data/Non Demented/OAS...      0\n/kaggle/input/imagesoasis/Data/Non Demented/OAS...      0\n/kaggle/input/imagesoasis/Data/Non Demented/OAS...      0\n/kaggle/input/imagesoasis/Data/Non Demented/OAS...      0\n/kaggle/input/imagesoasis/Data/Non Demented/OAS...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0302_MR1_mpr-3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0114_MR1_mpr-1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0150_MR1_mpr-3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0253_MR1_mpr-3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>/kaggle/input/imagesoasis/Data/Non Demented/OAS1_0349_MR1_mpr-4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming df is your DataFrame and 'class' is your target feature\nX = df_all.drop('Class', axis=1)\ny = df_all['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.712164Z","iopub.execute_input":"2024-03-28T09:44:25.712508Z","iopub.status.idle":"2024-03-28T09:44:25.733491Z","shell.execute_reply.started":"2024-03-28T09:44:25.712478Z","shell.execute_reply":"2024-03-28T09:44:25.732624Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_test_train(img_dict, y_train, y_test):\n    X_train_n = []\n    y_train_n = []\n    X_test_n = []\n    y_test_n = []\n    for ind in y_test.index:\n        paths = img_dict[ind]\n        imgs = []\n        for j in range(1,len(paths)):\n            img = Image.open(paths[j]).resize((128,128))\n            img = np.array(img)\n            imgs.append(img)\n            #y_test_n.append(y_test[ind])\n        X_test_n.append(imgs)\n        \n    print('first part done')\n    for ind in y_train.index:\n        paths = img_dict[ind]\n        imgs = []\n        for j in range(1,len(paths)):\n            img = Image.open(paths[j]).resize((128,128))\n            img = np.array(img)\n            imgs.append(img)\n            #y_train_n.append(y_train[ind])\n        X_train_n.append(imgs)\n    \n    \n    return X_train_n, X_test_n, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.734584Z","iopub.execute_input":"2024-03-28T09:44:25.734812Z","iopub.status.idle":"2024-03-28T09:44:25.742544Z","shell.execute_reply.started":"2024-03-28T09:44:25.734791Z","shell.execute_reply":"2024-03-28T09:44:25.741641Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = create_test_train(img_dict, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:44:25.743543Z","iopub.execute_input":"2024-03-28T09:44:25.743806Z","iopub.status.idle":"2024-03-28T09:59:29.426068Z","shell.execute_reply.started":"2024-03-28T09:44:25.743774Z","shell.execute_reply":"2024-03-28T09:59:29.425232Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"first part done\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch\n# from torch import nn\n# import torch.nn.functional as F\n\n# # Assuming each image is 128x128x3\n# input_shape = (128, 128, 3)\n\n# # Define the CNN model\n# class CNNModel(nn.Module):\n#     def __init__(self):\n#         super(CNNModel, self).__init__()\n#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n#         self.pool = nn.MaxPool2d(2, 2)\n#         self.flatten = nn.Flatten()\n\n#     def forward(self, x):\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.flatten(x)\n#         return x\n\n# # Create 61 CNN models for the 61 input images\n# cnn_models = [CNNModel() for _ in range(61)]\n\n# # Create 61 inputs for the 61 input images\n# inputs = [torch.randn(input_shape).permute(2,0,1) for _ in range(61)]\n\n# # Extract features from each input using the corresponding CNN model\n# features = [model(inp) for model, inp in zip(cnn_models, inputs)]\n\n# # Concatenate all features together\n# concatenated = torch.cat(features, dim=1)\n\n# # Add a dense layer for final prediction\n# output_layer = nn.Linear(concatenated.size(1), 4)\n# output = output_layer(concatenated)\n\n# # Create the model\n# model = nn.ModuleList([*cnn_models, output_layer])\n\n# # Define the loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters())\n\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:29.427505Z","iopub.execute_input":"2024-03-28T09:59:29.427939Z","iopub.status.idle":"2024-03-28T09:59:29.433741Z","shell.execute_reply.started":"2024-03-28T09:59:29.427906Z","shell.execute_reply":"2024-03-28T09:59:29.432795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# for id_images, label in zip(X_train, y_train):\n#     outputs = model(*id_images)\n#     loss = nn.CrossEntropyLoss(outputs.unsqueeze(0), label)\n\n# # Switch to evaluation mode\n# model.eval()\n\n# # No need to track gradients for testing\n# with torch.no_grad():\n#     correct_predictions = 0\n#     total_predictions = 0\n\n#     for id_images, label in zip(X_test, y_test):\n#         outputs = model(*id_images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total_predictions += label.size(0)\n#         correct_predictions += (predicted == label).sum().item()\n\n#     print('Test Accuracy: %d %%' % (100 * correct_predictions / total_predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:29.436499Z","iopub.execute_input":"2024-03-28T09:59:29.436774Z","iopub.status.idle":"2024-03-28T09:59:29.464173Z","shell.execute_reply.started":"2024-03-28T09:59:29.436750Z","shell.execute_reply":"2024-03-28T09:59:29.463341Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\nx_train = torch.from_numpy(np.array(X_train))\ny_train = torch.from_numpy(np.array(y_train))\nx_test = torch.from_numpy(np.array(X_test))\ny_test = torch.from_numpy(np.array(y_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:29.465237Z","iopub.execute_input":"2024-03-28T09:59:29.465562Z","iopub.status.idle":"2024-03-28T09:59:37.461178Z","shell.execute_reply.started":"2024-03-28T09:59:29.465530Z","shell.execute_reply":"2024-03-28T09:59:37.460159Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:37.462286Z","iopub.execute_input":"2024-03-28T09:59:37.462713Z","iopub.status.idle":"2024-03-28T09:59:37.468699Z","shell.execute_reply.started":"2024-03-28T09:59:37.462687Z","shell.execute_reply":"2024-03-28T09:59:37.467906Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"torch.Size([1133, 61, 128, 128, 3])"},"metadata":{}}]},{"cell_type":"code","source":"print('Time to run the network')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:37.470023Z","iopub.execute_input":"2024-03-28T09:59:37.470439Z","iopub.status.idle":"2024-03-28T09:59:37.481087Z","shell.execute_reply.started":"2024-03-28T09:59:37.470409Z","shell.execute_reply":"2024-03-28T09:59:37.480240Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Time to run the network\n","output_type":"stream"}]},{"cell_type":"code","source":"del path0\ndel path1\ndel path2\ndel path3\ndel X_train, X_test","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:37.482138Z","iopub.execute_input":"2024-03-28T09:59:37.482438Z","iopub.status.idle":"2024-03-28T09:59:37.527804Z","shell.execute_reply.started":"2024-03-28T09:59:37.482416Z","shell.execute_reply":"2024-03-28T09:59:37.526922Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"del df_all, img_dict","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:37.537912Z","iopub.execute_input":"2024-03-28T09:59:37.538171Z","iopub.status.idle":"2024-03-28T09:59:37.547084Z","shell.execute_reply.started":"2024-03-28T09:59:37.538149Z","shell.execute_reply":"2024-03-28T09:59:37.546240Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del X, y","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:59:37.547966Z","iopub.execute_input":"2024-03-28T09:59:37.548220Z","iopub.status.idle":"2024-03-28T09:59:37.562317Z","shell.execute_reply.started":"2024-03-28T09:59:37.548177Z","shell.execute_reply":"2024-03-28T09:59:37.561479Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice = torch.device(\"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:40:15.966849Z","iopub.execute_input":"2024-03-28T10:40:15.967750Z","iopub.status.idle":"2024-03-28T10:40:15.972764Z","shell.execute_reply.started":"2024-03-28T10:40:15.967713Z","shell.execute_reply":"2024-03-28T10:40:15.971661Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# Define your custom dataset\nclass MyDataset(Dataset):\n    def __init__(self, images, labels):\n        self.images = images\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.images[idx], self.labels[idx]\n\n# Assuming x_train, y_train, x_test, y_test are your data\ntrain_dataset = MyDataset(x_train, y_train)\ntest_dataset = MyDataset(x_test, y_test)\n\n# Create DataLoaders for training and testing\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Define the neural network\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Change 1 to 3\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.rnn = nn.GRU(64*32*32, 256, num_layers=2, batch_first=True)\n        self.fc = nn.Linear(256, 4)\n\n    def forward(self, x):\n        batch_size, timesteps, C, H, W = x.size()\n        x = x.view(batch_size * timesteps, C, H, W)\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.reshape(batch_size, timesteps, -1)  # Use reshape instead of view\n        x, _ = self.rnn(x)\n        x = x[:, -1, :]\n        x = torch.sigmoid(self.fc(x))\n        return x\n\n\n\n# Instantiate the network\nmodel = Net().to(device)\n\n# Define the loss function and the optimizer\ncriterion = nn.BCELoss()\nlr = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr = lr)\n\n\n# Initialize empty lists to store losses\ntrain_losses = []\ntest_losses = []\n\n# Training loop\nfor epoch in range(10):  # loop over the dataset multiple times\n    running_loss = 0.0\n    model.train()  # Set the model to training mode\n    for i, data in enumerate(train_dataloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n        inputs = inputs.float()\n        inputs = inputs.permute(0,1,4,2,3)\n        # Convert labels to one-hot encoding\n        labels_onehot = torch.zeros(labels.size(0), 4, device = device)\n        labels_onehot.scatter_(1, labels.view(-1,1), 1)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, labels_onehot)\n        loss.backward()\n        optimizer.step()\n        # Compute training loss\n        train_losses.append(loss.item())\n        # print statistics\n        running_loss += loss.item()\n    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader)}')\n\n    # Compute test loss\n    #test_loss = 0.0\n    #model.eval()  # Set the model to evaluation mode\n    #with torch.no_grad():  # Do not compute gradients for these operations\n    #    for i, data in enumerate(test_dataloader, 0):\n    #        inputs, labels = data\n    #        inputs = inputs.float()\n    #        inputs = inputs.permute(0,1,4,2,3)\n    #        labels_onehot = torch.zeros(labels.size(0), 4,device = device)\n    #        labels_onehot.scatter_(1, labels.view(-1,1), 1)\n    #        outputs = model(inputs)\n    #        loss = criterion(outputs, labels_onehot)\n    #        test_loss += loss.item()\n    #        test_losses.append(test_loss / len(test_dataloader))  # Store the test loss\n    #print(f'Epoch {epoch+1}, test loss: {test_loss/len(test_dataloader)}')\n\nprint('Finished Training')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T10:40:17.447644Z","iopub.execute_input":"2024-03-28T10:40:17.447996Z","iopub.status.idle":"2024-03-28T13:25:06.231596Z","shell.execute_reply.started":"2024-03-28T10:40:17.447966Z","shell.execute_reply":"2024-03-28T13:25:06.230399Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1, training loss: 0.3337417563630475\nEpoch 1, test loss: 0.3103690461979972\nEpoch 2, training loss: 0.30825647670361733\nEpoch 2, test loss: 0.31183818313810563\nEpoch 3, training loss: 0.3101722101370494\nEpoch 3, test loss: 0.3062293595737881\nEpoch 4, training loss: 0.3063674428396755\nEpoch 4, test loss: 0.3121926734844844\nEpoch 5, training loss: 0.3100707820720143\nEpoch 5, test loss: 0.3129917085170746\nEpoch 6, training loss: 0.307182014402416\nEpoch 6, test loss: 0.3063543852832582\nEpoch 7, training loss: 0.30885093038280803\nEpoch 7, test loss: 0.3064671771393882\nEpoch 8, training loss: 0.3078494978447755\nEpoch 8, test loss: 0.30964656008614433\nEpoch 9, training loss: 0.3129097914530171\nEpoch 9, test loss: 0.30779213706652325\nEpoch 10, training loss: 0.31033505251010257\nEpoch 10, test loss: 0.3100193540255229\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-28T13:32:09.699992Z","iopub.execute_input":"2024-03-28T13:32:09.700369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\n# Define your custom dataset\nclass MyDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image, label = self.images[idx], self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Assuming x_train, y_train, x_test, y_test are your data\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = MyDataset(x_train, y_train, transform=transform)\ntest_dataset = MyDataset(x_test, y_test, transform=transforms.ToTensor())\n\n\n# Create DataLoaders for training and testing\ntrain_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# Define the neural network with dropout\nclass Net(nn.Module):\n    def __init__(self, dropout_prob=0.5):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.dropout = nn.Dropout(p=dropout_prob)  # Dropout layer\n        self.rnn = nn.GRU(64*32*32, 256, num_layers=2, batch_first=True)\n        self.fc = nn.Linear(256, 4)\n\n    def forward(self, x):\n        batch_size, timesteps, C, H, W = x.size()\n        x = x.view(batch_size * timesteps, C, H, W)\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.reshape(batch_size, timesteps, -1)\n        x, _ = self.rnn(x)\n        x = x[:, -1, :]\n        x = torch.sigmoid(self.fc(x))\n        return x\n\n# Instantiate the network and move it to the device\nmodel = Net().to(device)\n\n# Define the loss function and the optimizer\ncriterion = nn.BCELoss()\nlr = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n# Initialize empty lists to store losses\ntrain_losses = []\ntest_losses = []\n\n# Training loop\nfor epoch in range(10):\n    running_loss = 0.0\n    model.train()\n    for i, data in enumerate(train_dataloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n        inputs = inputs.float()\n        inputs = inputs.permute(0, 1, 4, 2, 3)\n        labels_onehot = torch.zeros(labels.size(0), 4, device=device)\n        labels_onehot.scatter_(1, labels.view(-1, 1), 1)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels_onehot)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        # Compute training loss\n        train_losses.append(loss.item())\n    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader)}')\n\n    \nprint('Finished Training')\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-28T13:25:06.233655Z","iopub.execute_input":"2024-03-28T13:25:06.234054Z","iopub.status.idle":"2024-03-28T13:25:06.240955Z","shell.execute_reply.started":"2024-03-28T13:25:06.234015Z","shell.execute_reply":"2024-03-28T13:25:06.239847Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix, classification_report\n\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    raw_outputs = model(x_test.float().permute(0,1,4,2,3))  # Raw output (logits) from the model\n    predicted_probs = torch.sigmoid(raw_outputs)  # Apply sigmoid to get probabilities\n\n\n# Assuming you have predictions (predicted_probs) and ground truth labels (y_test)\nthreshold = 0.5  # Set your desired threshold for converting probabilities to binary labels\npredicted_labels = (predicted_probs > threshold).astype(int)\n\n# Compute multilabel confusion matrix\nmcm = multilabel_confusion_matrix(y_test, predicted_labels)\n\n# Print confusion matrix for each class\nfor i, label in enumerate([\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"]):\n    print(f\"Confusion matrix for {label}:\\n{mcm[i]}\")\n\n# Compute classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, predicted_labels))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}