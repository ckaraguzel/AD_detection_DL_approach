{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run python file Create_Val_Test_Train.py to create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "\n",
    "df_train = np.load('df_train.npy')\n",
    "df_validation = np.load('df_validation.npy')\n",
    "df_test = np.load('df_test.npy')\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "# Define your custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "X_train = df_train[:,3]\n",
    "y_train = df_train[:,2]\n",
    "# Create dataset\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "# Create DataLoaders for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "del X_train\n",
    "X_test = df_test[:,3]\n",
    "y_test = df_test[:,2]\n",
    "X_val = df_validation[:,3]\n",
    "y_val = df_validation[:,2]\n",
    "val_dataset = MyDataset(X_val, y_val)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=30720, out_features=65, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=65, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Simple model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(65, 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128*240, 65) \n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
    "        self.fc3 = nn.Linear(65, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Initialize the network and print its architecture\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     25\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[38;5;241m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:183\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(batch, \u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Initialize the network and print its architecture\n",
    "model = Net()\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.5,1.0]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# Initialize empty lists to store losses\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        l1_lambda = 0.0005\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss+=l1_lambda*l1_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Compute training loss\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "# Now without regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "# Training loop\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Compute training loss\n",
    "        train_losses.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def find_optimal_threshold(predictions, y_test):\n",
    "    min_sum = float('inf')\n",
    "    optimal_threshold = 0.5\n",
    "    # Iterate over possible thresholds from 0 to 1\n",
    "    for threshold in np.arange(0.3, 0.8, 0.001):\n",
    "        # Apply threshold\n",
    "        preds = (np.array(predictions)[:,1] > threshold).astype(int)\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        # Compute sum of off-diagonal elements\n",
    "        off_diagonal_sum = 164 - np.trace(cm)\n",
    "        # Update optimal threshold if this threshold is better\n",
    "        if off_diagonal_sum < min_sum and cm[1][1]/np.sum(cm[1]) >=0.5:\n",
    "            min_sum = off_diagonal_sum\n",
    "            optimal_threshold = threshold\n",
    "\n",
    "    return optimal_threshold\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "output = []\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        outputs = model(data[0].float().to(device)).to(device)\n",
    "        predicted = torch.softmax(outputs, dim = 1) # Apply a threshold\n",
    "        predictions.extend(predicted.tolist())\n",
    "        output.extend(outputs.tolist())\n",
    "\n",
    "        \n",
    "optimal_threshold = find_optimal_threshold(predictions, y_val.astype(int))\n",
    "# Calculate the confusion matrix\n",
    "mcm = confusion_matrix(y_val.astype(int), (np.array(predictions)[:,1]>optimal_threshold).astype(int))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "for i, matrix in enumerate(mcm):\n",
    "    print(f'Class {i}:')\n",
    "    print(matrix)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "output = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        outputs = model(data.float().to(device)).to(device)\n",
    "        predicted = torch.softmax(outputs, dim = 1) # Apply a threshold\n",
    "        predictions.extend(predicted.tolist())\n",
    "        output.extend(outputs.tolist())\n",
    "# Calculate the confusion matrix\n",
    "mcm = confusion_matrix(y_test.astype(int), (np.array(predictions)[:,1]>optimal_threshold).astype(int))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "for i, matrix in enumerate(mcm):\n",
    "    print(f'Class {i}:')\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Convert tensors to numpy arrays for sklearn\n",
    "outputs_np = (np.array(predictions)[:,1]>optimal_threshold).astype(int)\n",
    "labels_np = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy = accuracy_score(labels_np, outputs_np)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "print(\"ROC AUC score:\", roc_auc_score(labels_np, outputs_np))\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(labels_np, outputs_np))\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(labels_np, outputs_np)\n",
    "print(\"Precision, Recall, Fscore:\", precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose this is your DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'c1': df_test[:,0],  \n",
    "    'c2': outputs_np \n",
    "})\n",
    "# Convert 'c2' column to string type\n",
    "df['c2'] = df['c2'].astype(str)\n",
    "# Create a countplot\n",
    "sns.countplot(x='c1', hue='c2', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCI vs CN -- ADNI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability output and then add two features to xgboost model and try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for model 2. Can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = original_model.conv1\n",
    "        self.fc1 = original_model.fc1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Create the new model\n",
    "new_model = MyModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_train = []\n",
    "for data in train_dataloader:\n",
    "    input_data = data[0].float()\n",
    "    labels_train.append(data[1])\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "flattened_labels = np.concatenate(labels_train, axis = 0)\n",
    "del outputs, output\n",
    "np.save('vectorized_train.npy', flattened_outputs)\n",
    "np.save('vectorized_tr_labels.npy', flattened_labels)\n",
    "\n",
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_val = []\n",
    "for data in valloader:\n",
    "    input_data = data[0].float()\n",
    "    labels_val.append(data[1])\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "flattened_labels = np.concatenate(labels_val, axis = 0)\n",
    "del outputs, output\n",
    "np.save('vectorized_val.npy', flattened_outputs)\n",
    "np.save('vectorized_val_labels.npy', flattened_labels)\n",
    "\n",
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_train = []\n",
    "for data in testloader:\n",
    "    input_data = data.float()\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "del outputs, output\n",
    "np.save('vectorized_test.npy', flattened_outputs)\n",
    "np.save('y_test.npy', y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the second model. Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('vectorized_train.npy')\n",
    "y_train = np.load('vectorized_tr_labels.npy')\n",
    "X_val = np.load('vectorized_val.npy')\n",
    "y_val = np.load('vectorized_val_labels.npy')\n",
    "X_test = np.load('vectorized_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "\n",
    "df_train = np.load('df_train.npy')\n",
    "df_validation = np.load('df_validation.npy')\n",
    "df_test = np.load('df_test.npy')\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "# Convert the 'sex' column from string to int\n",
    "df_train[:,0] = (df_train[:,0]=='M').astype(int)\n",
    "df_validation[:,0] = (df_validation[:,0]=='M').astype(int)\n",
    "df_test[:,0] = (df_test[:,0]=='M').astype(int)\n",
    "# Add the 'sex' and 'age' columns to your X_train and X_val\n",
    "X_train = np.hstack((X_train, df_train[:,0:2]))\n",
    "X_val = np.hstack((X_val, df_validation[:,0:2]))\n",
    "X_test = np.hstack((X_test, df_test[:,0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 27 is smaller than n_iter=100. Running 27 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "{'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.01}\n",
      "[0]\tvalidation_0-logloss:0.68638\n",
      "[1]\tvalidation_0-logloss:0.68015\n",
      "[2]\tvalidation_0-logloss:0.67383\n",
      "[3]\tvalidation_0-logloss:0.66776\n",
      "[4]\tvalidation_0-logloss:0.66166\n",
      "[5]\tvalidation_0-logloss:0.65558\n",
      "[6]\tvalidation_0-logloss:0.64983\n",
      "[7]\tvalidation_0-logloss:0.64379\n",
      "[8]\tvalidation_0-logloss:0.63798\n",
      "[9]\tvalidation_0-logloss:0.63246\n",
      "[10]\tvalidation_0-logloss:0.62688\n",
      "[11]\tvalidation_0-logloss:0.62142\n",
      "[12]\tvalidation_0-logloss:0.61639\n",
      "[13]\tvalidation_0-logloss:0.61130\n",
      "[14]\tvalidation_0-logloss:0.60652\n",
      "[15]\tvalidation_0-logloss:0.60145\n",
      "[16]\tvalidation_0-logloss:0.59659\n",
      "[17]\tvalidation_0-logloss:0.59195\n",
      "[18]\tvalidation_0-logloss:0.58733\n",
      "[19]\tvalidation_0-logloss:0.58256\n",
      "[20]\tvalidation_0-logloss:0.57843\n",
      "[21]\tvalidation_0-logloss:0.57383\n",
      "[22]\tvalidation_0-logloss:0.56951\n",
      "[23]\tvalidation_0-logloss:0.56510\n",
      "[24]\tvalidation_0-logloss:0.56109\n",
      "[25]\tvalidation_0-logloss:0.55700\n",
      "[26]\tvalidation_0-logloss:0.55297\n",
      "[27]\tvalidation_0-logloss:0.54905\n",
      "[28]\tvalidation_0-logloss:0.54523\n",
      "[29]\tvalidation_0-logloss:0.54146\n",
      "[30]\tvalidation_0-logloss:0.53785\n",
      "[31]\tvalidation_0-logloss:0.53418\n",
      "[32]\tvalidation_0-logloss:0.53040\n",
      "[33]\tvalidation_0-logloss:0.52687\n",
      "[34]\tvalidation_0-logloss:0.52340\n",
      "[35]\tvalidation_0-logloss:0.52011\n",
      "[36]\tvalidation_0-logloss:0.51661\n",
      "[37]\tvalidation_0-logloss:0.51342\n",
      "[38]\tvalidation_0-logloss:0.51020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39]\tvalidation_0-logloss:0.50676\n",
      "[40]\tvalidation_0-logloss:0.50388\n",
      "[41]\tvalidation_0-logloss:0.50066\n",
      "[42]\tvalidation_0-logloss:0.49776\n",
      "[43]\tvalidation_0-logloss:0.49483\n",
      "[44]\tvalidation_0-logloss:0.49196\n",
      "[45]\tvalidation_0-logloss:0.48887\n",
      "[46]\tvalidation_0-logloss:0.48638\n",
      "[47]\tvalidation_0-logloss:0.48347\n",
      "[48]\tvalidation_0-logloss:0.48081\n",
      "[49]\tvalidation_0-logloss:0.47822\n",
      "[50]\tvalidation_0-logloss:0.47539\n",
      "[51]\tvalidation_0-logloss:0.47304\n",
      "[52]\tvalidation_0-logloss:0.47031\n",
      "[53]\tvalidation_0-logloss:0.46807\n",
      "[54]\tvalidation_0-logloss:0.46539\n",
      "[55]\tvalidation_0-logloss:0.46297\n",
      "[56]\tvalidation_0-logloss:0.46067\n",
      "[57]\tvalidation_0-logloss:0.45830\n",
      "[58]\tvalidation_0-logloss:0.45604\n",
      "[59]\tvalidation_0-logloss:0.45384\n",
      "[60]\tvalidation_0-logloss:0.45142\n",
      "[61]\tvalidation_0-logloss:0.44928\n",
      "[62]\tvalidation_0-logloss:0.44716\n",
      "[63]\tvalidation_0-logloss:0.44494\n",
      "[64]\tvalidation_0-logloss:0.44308\n",
      "[65]\tvalidation_0-logloss:0.44085\n",
      "[66]\tvalidation_0-logloss:0.43895\n",
      "[67]\tvalidation_0-logloss:0.43702\n",
      "[68]\tvalidation_0-logloss:0.43512\n",
      "[69]\tvalidation_0-logloss:0.43311\n",
      "[70]\tvalidation_0-logloss:0.43137\n",
      "[71]\tvalidation_0-logloss:0.42945\n",
      "[72]\tvalidation_0-logloss:0.42777\n",
      "[73]\tvalidation_0-logloss:0.42584\n",
      "[74]\tvalidation_0-logloss:0.42438\n",
      "[75]\tvalidation_0-logloss:0.42251\n",
      "[76]\tvalidation_0-logloss:0.42097\n",
      "[77]\tvalidation_0-logloss:0.41930\n",
      "[78]\tvalidation_0-logloss:0.41781\n",
      "[79]\tvalidation_0-logloss:0.41640\n",
      "[80]\tvalidation_0-logloss:0.41488\n",
      "[81]\tvalidation_0-logloss:0.41331\n",
      "[82]\tvalidation_0-logloss:0.41171\n",
      "[83]\tvalidation_0-logloss:0.41047\n",
      "[84]\tvalidation_0-logloss:0.40907\n",
      "[85]\tvalidation_0-logloss:0.40741\n",
      "[86]\tvalidation_0-logloss:0.40600\n",
      "[87]\tvalidation_0-logloss:0.40460\n",
      "[88]\tvalidation_0-logloss:0.40334\n",
      "[89]\tvalidation_0-logloss:0.40158\n",
      "[90]\tvalidation_0-logloss:0.40030\n",
      "[91]\tvalidation_0-logloss:0.39899\n",
      "[92]\tvalidation_0-logloss:0.39776\n",
      "[93]\tvalidation_0-logloss:0.39629\n",
      "[94]\tvalidation_0-logloss:0.39513\n",
      "[95]\tvalidation_0-logloss:0.39387\n",
      "[96]\tvalidation_0-logloss:0.39266\n",
      "[97]\tvalidation_0-logloss:0.39127\n",
      "[98]\tvalidation_0-logloss:0.39021\n",
      "[99]\tvalidation_0-logloss:0.38910\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "np.random.seed(42)\n",
    "# Your data and labels\n",
    "data = np.vstack((X_train,X_val))\n",
    "labels = np.hstack((y_train,y_val))\n",
    "\n",
    "# Split the data into training and testing sets first\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "scale_pos_weight = sum(labels_train == 0) / sum(labels_train == 1)\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',  # Objective function for binary classification\n",
    "    scale_pos_weight = scale_pos_weight,\n",
    "    random_state=42  # Random seed\n",
    ")\n",
    "\n",
    "# Define the parameter grid for RandomSearch\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 5],  # Maximum depth of the trees\n",
    "    'learning_rate': [0.001, 0.005, 0.01],  # Learning rate (eta)\n",
    "    'n_estimators': [50, 75, 100]  # Number of training rounds\n",
    "}\n",
    "\n",
    "# Initialize RandomSearch\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=100, scoring='roc_auc', n_jobs=-1, cv=5, verbose=3)\n",
    "\n",
    "# Perform RandomSearch\n",
    "random_search.fit(data_train, labels_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Train the model with early stopping using the best found parameters\n",
    "model = random_search.best_estimator_\n",
    "eval_set = [(data_test, labels_test)]  # Validation set for early stopping\n",
    "model.fit(data_train, labels_train, eval_metric=\"logloss\", eval_set=eval_set)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_prob = model.predict_proba(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Make predictions on the test set\n",
    "def find_optimal_threshold(predictions, y_test):\n",
    "    min_sum = float('inf')\n",
    "    optimal_threshold = 0.5\n",
    "\n",
    "    # Iterate over possible thresholds from 0 to 1\n",
    "    for threshold in np.arange(0.3, 0.8, 0.001):\n",
    "        # Apply threshold\n",
    "        preds = (np.array(predictions)[:,1] > threshold).astype(int)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "        # Compute sum of off-diagonal elements\n",
    "        off_diagonal_sum = 164 - np.trace(cm)\n",
    "        #print(cm)\n",
    "        # Update optimal threshold if this threshold is better\n",
    "        if off_diagonal_sum < min_sum and cm[1][1]/np.sum(cm[1]) >0.5:\n",
    "            min_sum = off_diagonal_sum\n",
    "            optimal_threshold = threshold\n",
    "\n",
    "    return optimal_threshold\n",
    "\n",
    "threshold = find_optimal_threshold(preds_prob, labels_test)\n",
    "preds = (preds_prob[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8700607902735563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 11],\n",
       "       [ 7, 42]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.92222222, 0.79245283]),\n",
       " array([0.88297872, 0.85714286]),\n",
       " array([0.90217391, 0.82352941]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(labels_test, preds)\n",
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6071211199026172"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict_proba(X_test)\n",
    "preds = (pred_test[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37, 16],\n",
       "       [15, 16]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.71153846, 0.5       ]),\n",
       " array([0.69811321, 0.51612903]),\n",
       " array([0.7047619 , 0.50793651]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(y_test, preds)\n",
    "precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'c1': df_test[:,0],  \n",
    "    'c2': preds \n",
    "})\n",
    "# Convert 'c2' column to string type\n",
    "df['c2'] = df['c2'].astype(str)\n",
    "# Create a countplot\n",
    "sns.countplot(x='c1', hue='c2', data=df)\n",
    "# Replace the x-axis labels\n",
    "plt.xticks([0, 1], ['M', 'F'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define your custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Simple model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(65, 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128*240, 65) \n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
    "        self.fc3 = nn.Linear(65, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Initialize the network and print its architecture\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 3.1844\n",
      "Epoch 2, training loss: 2.3908\n",
      "Epoch 3, training loss: 1.7668\n",
      "Epoch 4, training loss: 1.3303\n",
      "Epoch 5, training loss: 1.0994\n",
      "Epoch 6, training loss: 0.9849\n",
      "Epoch 7, training loss: 0.9217\n",
      "Epoch 8, training loss: 0.8837\n",
      "Epoch 9, training loss: 0.8588\n",
      "Epoch 10, training loss: 0.8528\n",
      "Epoch 11, training loss: 0.8119\n",
      "Epoch 12, training loss: 0.8082\n",
      "Epoch 13, training loss: 0.7965\n",
      "Epoch 14, training loss: 0.7730\n",
      "Epoch 15, training loss: 0.7882\n",
      "Epoch 1, training loss: 0.6745\n",
      "Epoch 2, training loss: 0.6380\n",
      "Epoch 3, training loss: 0.5317\n",
      "Epoch 4, training loss: 0.4831\n",
      "Epoch 5, training loss: 0.3654\n",
      "Epoch 6, training loss: 0.3228\n",
      "Epoch 7, training loss: 0.2624\n",
      "Epoch 8, training loss: 0.2085\n",
      "Epoch 9, training loss: 0.2725\n",
      "Epoch 10, training loss: 0.2122\n",
      "Epoch 11, training loss: 0.1887\n",
      "Epoch 12, training loss: 0.1904\n",
      "Epoch 13, training loss: 0.2461\n",
      "Epoch 14, training loss: 0.1369\n",
      "Epoch 15, training loss: 0.1002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the features and labels from the training data\n",
    "X_train = df_train[:,3]\n",
    "y_train = df_train[:,2]\n",
    "\n",
    "# Create a dataset from the training data\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Delete the original training features to save memory\n",
    "del X_train\n",
    "\n",
    "# Extract the features and labels from the test and validation data\n",
    "X_test = df_test[:,3]\n",
    "y_test = df_test[:,2]\n",
    "X_val = df_validation[:,3]\n",
    "y_val = df_validation[:,2]\n",
    "\n",
    "# Create datasets from the validation and test data\n",
    "val_dataset = MyDataset(X_val, y_val)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(X_test, batch_size=32)\n",
    "\n",
    "# Initialize the network\n",
    "model = Net()\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([0.5,1.0]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# Initialize a list to store the training losses\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # Get the inputs and labels from the current batch of data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()  # Convert the inputs to float\n",
    "        labels = labels.type(torch.LongTensor)   # Cast the labels to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move the inputs and labels to the device\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the L1 norm of the model parameters\n",
    "        l1_lambda = 0.0005\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss += l1_lambda * l1_norm  # Add the L1 regularization term to the loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Store the loss for this batch\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    # Print the average training loss for this epoch\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')\n",
    "\n",
    "# Now train the model without L1 regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # Get the inputs and labels from the current batch of data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.float()  # Convert the inputs to float\n",
    "        labels = labels.type(torch.LongTensor)   # Cast the labels to long\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move the inputs and labels to the device\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Store the loss for this batch\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Print the average training loss for this epoch\n",
    "    print(f'Epoch {epoch+1}, training loss: {running_loss/len(train_dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability outputs\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = original_model.conv1\n",
    "        self.fc1 = original_model.fc1\n",
    "        self.dropout = original_model.dropout\n",
    "        self.fc3 = original_model.fc3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 65, 256, 240)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create the new model\n",
    "new_model = MyModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_train = []\n",
    "for data in train_dataloader:\n",
    "    input_data = data[0].float()\n",
    "    labels_train.append(data[1])\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "flattened_labels = np.concatenate(labels_train, axis = 0)\n",
    "del outputs, output\n",
    "np.save('probs_train.npy', flattened_outputs)\n",
    "np.save('tr_labels.npy', flattened_labels)\n",
    "\n",
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_val = []\n",
    "for data in valloader:\n",
    "    input_data = data[0].float()\n",
    "    labels_val.append(data[1])\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "flattened_labels = np.concatenate(labels_val, axis = 0)\n",
    "del outputs, output\n",
    "np.save('probs_val.npy', flattened_outputs)\n",
    "np.save('val_labels.npy', flattened_labels)\n",
    "\n",
    "outputs = [] #stores one feature/value for each image for each patient.  Shape is (*,65).\n",
    "labels_train = []\n",
    "for data in testloader:\n",
    "    input_data = data.float()\n",
    "    output = new_model(input_data.to(device))\n",
    "    outputs.append(output.detach().cpu().numpy()) \n",
    "flattened_outputs = np.concatenate(outputs, axis=0)\n",
    "del outputs, output\n",
    "np.save('probs_test.npy', flattened_outputs)\n",
    "np.save('y_test.npy', y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best parameters found:  {'reg_lambda': 1, 'reg_alpha': 0.1, 'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.01}\n",
      "[0]\tvalidation_0-logloss:0.68659\n",
      "[1]\tvalidation_0-logloss:0.68017\n",
      "[2]\tvalidation_0-logloss:0.67389\n",
      "[3]\tvalidation_0-logloss:0.66773\n",
      "[4]\tvalidation_0-logloss:0.66170\n",
      "[5]\tvalidation_0-logloss:0.65564\n",
      "[6]\tvalidation_0-logloss:0.64985\n",
      "[7]\tvalidation_0-logloss:0.64402\n",
      "[8]\tvalidation_0-logloss:0.63846\n",
      "[9]\tvalidation_0-logloss:0.63286\n",
      "[10]\tvalidation_0-logloss:0.62752\n",
      "[11]\tvalidation_0-logloss:0.62214\n",
      "[12]\tvalidation_0-logloss:0.61686\n",
      "[13]\tvalidation_0-logloss:0.61183\n",
      "[14]\tvalidation_0-logloss:0.60675\n",
      "[15]\tvalidation_0-logloss:0.60191\n",
      "[16]\tvalidation_0-logloss:0.59703\n",
      "[17]\tvalidation_0-logloss:0.59237\n",
      "[18]\tvalidation_0-logloss:0.58767\n",
      "[19]\tvalidation_0-logloss:0.58318\n",
      "[20]\tvalidation_0-logloss:0.57866\n",
      "[21]\tvalidation_0-logloss:0.57434\n",
      "[22]\tvalidation_0-logloss:0.56999\n",
      "[23]\tvalidation_0-logloss:0.56575\n",
      "[24]\tvalidation_0-logloss:0.56167\n",
      "[25]\tvalidation_0-logloss:0.55755\n",
      "[26]\tvalidation_0-logloss:0.55354\n",
      "[27]\tvalidation_0-logloss:0.54957\n",
      "[28]\tvalidation_0-logloss:0.54596\n",
      "[29]\tvalidation_0-logloss:0.54214\n",
      "[30]\tvalidation_0-logloss:0.53867\n",
      "[31]\tvalidation_0-logloss:0.53498\n",
      "[32]\tvalidation_0-logloss:0.53144\n",
      "[33]\tvalidation_0-logloss:0.52797\n",
      "[34]\tvalidation_0-logloss:0.52448\n",
      "[35]\tvalidation_0-logloss:0.52114\n",
      "[36]\tvalidation_0-logloss:0.51786\n",
      "[37]\tvalidation_0-logloss:0.51465\n",
      "[38]\tvalidation_0-logloss:0.51149\n",
      "[39]\tvalidation_0-logloss:0.50839\n",
      "[40]\tvalidation_0-logloss:0.50535\n",
      "[41]\tvalidation_0-logloss:0.50227\n",
      "[42]\tvalidation_0-logloss:0.49934\n",
      "[43]\tvalidation_0-logloss:0.49647\n",
      "[44]\tvalidation_0-logloss:0.49365\n",
      "[45]\tvalidation_0-logloss:0.49088\n",
      "[46]\tvalidation_0-logloss:0.48816\n",
      "[47]\tvalidation_0-logloss:0.48539\n",
      "[48]\tvalidation_0-logloss:0.48277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetu\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\tvalidation_0-logloss:0.48020\n",
      "[50]\tvalidation_0-logloss:0.47768\n",
      "[51]\tvalidation_0-logloss:0.47520\n",
      "[52]\tvalidation_0-logloss:0.47266\n",
      "[53]\tvalidation_0-logloss:0.47018\n",
      "[54]\tvalidation_0-logloss:0.46783\n",
      "[55]\tvalidation_0-logloss:0.46553\n",
      "[56]\tvalidation_0-logloss:0.46327\n",
      "[57]\tvalidation_0-logloss:0.46105\n",
      "[58]\tvalidation_0-logloss:0.45878\n",
      "[59]\tvalidation_0-logloss:0.45664\n",
      "[60]\tvalidation_0-logloss:0.45455\n",
      "[61]\tvalidation_0-logloss:0.45249\n",
      "[62]\tvalidation_0-logloss:0.45064\n",
      "[63]\tvalidation_0-logloss:0.44855\n",
      "[64]\tvalidation_0-logloss:0.44677\n",
      "[65]\tvalidation_0-logloss:0.44476\n",
      "[66]\tvalidation_0-logloss:0.44304\n",
      "[67]\tvalidation_0-logloss:0.44110\n",
      "[68]\tvalidation_0-logloss:0.43945\n",
      "[69]\tvalidation_0-logloss:0.43758\n",
      "[70]\tvalidation_0-logloss:0.43599\n",
      "[71]\tvalidation_0-logloss:0.43418\n",
      "[72]\tvalidation_0-logloss:0.43266\n",
      "[73]\tvalidation_0-logloss:0.43091\n",
      "[74]\tvalidation_0-logloss:0.42945\n",
      "[75]\tvalidation_0-logloss:0.42776\n",
      "[76]\tvalidation_0-logloss:0.42636\n",
      "[77]\tvalidation_0-logloss:0.42472\n",
      "[78]\tvalidation_0-logloss:0.42338\n",
      "[79]\tvalidation_0-logloss:0.42180\n",
      "[80]\tvalidation_0-logloss:0.42051\n",
      "[81]\tvalidation_0-logloss:0.41899\n",
      "[82]\tvalidation_0-logloss:0.41775\n",
      "[83]\tvalidation_0-logloss:0.41629\n",
      "[84]\tvalidation_0-logloss:0.41488\n",
      "[85]\tvalidation_0-logloss:0.41347\n",
      "[86]\tvalidation_0-logloss:0.41233\n",
      "[87]\tvalidation_0-logloss:0.41096\n",
      "[88]\tvalidation_0-logloss:0.40987\n",
      "[89]\tvalidation_0-logloss:0.40855\n",
      "[90]\tvalidation_0-logloss:0.40751\n",
      "[91]\tvalidation_0-logloss:0.40624\n",
      "[92]\tvalidation_0-logloss:0.40523\n",
      "[93]\tvalidation_0-logloss:0.40400\n",
      "[94]\tvalidation_0-logloss:0.40304\n",
      "[95]\tvalidation_0-logloss:0.40189\n",
      "[96]\tvalidation_0-logloss:0.40073\n",
      "[97]\tvalidation_0-logloss:0.39983\n",
      "[98]\tvalidation_0-logloss:0.39871\n",
      "[99]\tvalidation_0-logloss:0.39786\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "# Load the training data\n",
    "X_train = np.load('probs_train.npy')\n",
    "y_train = np.load('tr_labels.npy')\n",
    "\n",
    "# Load the validation data\n",
    "X_val = np.load('probs_val.npy')\n",
    "y_val = np.load('val_labels.npy')\n",
    "\n",
    "# Load the test data\n",
    "X_test = np.load('probs_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Save the original np.load function\n",
    "np_load_old = np.load\n",
    "\n",
    "# Modify the default parameters of np.load to allow loading pickled data\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# Load the additional dataframes\n",
    "df_train = np.load('df_train.npy')\n",
    "df_validation = np.load('df_validation.npy')\n",
    "df_test = np.load('df_test.npy')\n",
    "\n",
    "# Restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "\n",
    "# Convert the 'sex' column from string to int\n",
    "# 'M' is converted to 1 and 'F' is converted to 0\n",
    "df_train[:,0] = (df_train[:,0]=='M').astype(int)\n",
    "df_validation[:,0] = (df_validation[:,0]=='M').astype(int)\n",
    "df_test[:,0] = (df_test[:,0]=='M').astype(int)\n",
    "\n",
    "# Add the 'sex' and 'age' columns to your X_train, X_val, and X_test\n",
    "# This enriches the feature set with demographic information\n",
    "X_train = np.hstack((X_train, df_train[:,0:2]))\n",
    "X_val = np.hstack((X_val, df_validation[:,0:2]))\n",
    "X_test = np.hstack((X_test, df_test[:,0:2]))\n",
    "\n",
    "# Import the necessary library\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Stack the training and validation data and labels\n",
    "data = np.vstack((X_train,X_val))\n",
    "labels = np.hstack((y_train,y_val))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# The test size is 30% of the total data\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the ratio of negative to positive instances in the training data\n",
    "scale_pos_weight = sum(labels_train == 0) / sum(labels_train == 1)\n",
    "\n",
    "# Define the XGBoost model with the objective function for binary classification\n",
    "# The scale_pos_weight parameter helps handle class imbalance\n",
    "# Regularization is added through the 'reg_alpha' and 'reg_lambda' parameters\n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight = scale_pos_weight,\n",
    "    random_state=42,\n",
    "    reg_alpha = 0.1,  # L1 regularization term on weight (analogous to Lasso regression)\n",
    "    reg_lambda = 1  # L2 regularization term on weight (analogous to Ridge regression)\n",
    ")\n",
    "\n",
    "# Define the parameter grid for RandomSearch\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 5, 7],  # Maximum depth of the trees\n",
    "    'learning_rate': [0.001, 0.002, 0.005, 0.01],  # Learning rate (eta)\n",
    "    'n_estimators': [50, 100, 200],  # Number of training rounds\n",
    "    'reg_alpha': [0.1, 0.5, 1],  # L1 regularization term on weight\n",
    "    'reg_lambda': [0.1, 0.5, 1]  # L2 regularization term on weight\n",
    "}\n",
    "\n",
    "# Initialize RandomSearch with the model, parameter grid, and other parameters\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=100, scoring='roc_auc', n_jobs=-1, cv=10, verbose=3)\n",
    "\n",
    "# Perform RandomSearch on the training data\n",
    "random_search.fit(data_train, labels_train)\n",
    "\n",
    "# Print the best parameters found by RandomSearch\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the model with early stopping using the best found parameters\n",
    "model = random_search.best_estimator_\n",
    "eval_set = [(data_test, labels_test)]  # Validation set for early stopping\n",
    "model.fit(data_train, labels_train, eval_metric=\"logloss\", eval_set=eval_set)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_prob = model.predict_proba(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.58%\n",
      "ROC AUC score: 0.8754098360655738\n",
      "Confusion matrix:\n",
      " [[58  3]\n",
      " [ 7 28]]\n",
      "Precision, Recall, Fscore: [0.89230769 0.90322581] [0.95081967 0.8       ] [0.92063492 0.84848485]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to find the optimal threshold for classification\n",
    "def find_optimal_threshold(predictions, y_test):\n",
    "    min_sum = float('inf')\n",
    "    optimal_threshold = 0.5\n",
    "\n",
    "    # Iterate over possible thresholds from 0.3 to 0.8\n",
    "    for threshold in np.arange(0.3, 0.8, 0.001):\n",
    "        # Apply threshold to the second column of predictions\n",
    "        preds = (np.array(predictions)[:,1] > threshold).astype(int)\n",
    "\n",
    "        # Compute confusion matrix for the current threshold\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "        # Compute sum of off-diagonal elements\n",
    "        off_diagonal_sum = 164 - np.trace(cm)\n",
    "\n",
    "        # Update optimal threshold if this threshold is better\n",
    "        if off_diagonal_sum < min_sum and cm[1][1]/np.sum(cm[1]) >0.5:\n",
    "            min_sum = off_diagonal_sum\n",
    "            optimal_threshold = threshold\n",
    "\n",
    "    # Return the optimal threshold\n",
    "    return optimal_threshold\n",
    "\n",
    "# Find the optimal threshold for the test set predictions\n",
    "threshold = find_optimal_threshold(preds_prob, labels_test)\n",
    "\n",
    "# Uncomment the next few lines to print results for validation dataset\n",
    "# Apply the optimal threshold to the second column of the test set predictions\n",
    "preds = (preds_prob[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "print(\"ROC AUC score:\", roc_auc_score(labels_test, preds))\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(labels_test, preds))\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(labels_test, preds)\n",
    "print(\"Precision, Recall, Fscore:\", precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.48%\n",
      "ROC AUC score: 0.5858186244674376\n",
      "Confusion matrix:\n",
      " [[45  8]\n",
      " [21 10]]\n",
      "Precision, Recall, Fscore: [0.68181818 0.55555556] [0.8490566  0.32258065] [0.75630252 0.40816327]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the original test set\n",
    "pred_test = model.predict_proba(X_test)\n",
    "\n",
    "# Apply the optimal threshold to the second column of the original test set predictions\n",
    "preds = (pred_test[:, 1]> threshold).astype(int)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "print(\"ROC AUC score:\", roc_auc_score(y_test, preds))\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "precision, recall, fscore, _ = score(y_test, preds)\n",
    "print(\"Precision, Recall, Fscore:\", precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'c1': df_test[:,0],  \n",
    "    'c2': preds \n",
    "})\n",
    "# Convert 'c2' column to string type\n",
    "df['c2'] = df['c2'].astype(str)\n",
    "# Create a countplot\n",
    "sns.countplot(x='c1', hue='c2', data=df)\n",
    "# Replace the x-axis labels\n",
    "plt.xticks([0, 1], ['M', 'F'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8209069,
     "datasetId": 4773921,
     "sourceId": 8092331,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
